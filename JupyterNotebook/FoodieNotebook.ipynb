{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXeFBI5Oo4E1"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ6_gA6koCQF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "from torchvision import models, transforms\n",
        "from datasets import load_dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ6J8HvLyxYr"
      },
      "outputs": [],
      "source": [
        "def is_grayscale(image):\n",
        "    return image.mode == 'L'\n",
        "\n",
        "def custom_collate(batch):\n",
        "    transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])\n",
        "\n",
        "    batch = [item for item in batch if not is_grayscale(item[\"image\"])]\n",
        "\n",
        "    images = [transform(item[\"image\"]) for item in batch]\n",
        "    labels = [item[\"label\"] for item in batch]\n",
        "\n",
        "    return {\"pixel_values\": torch.stack(images), \"label\": torch.tensor(labels)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeSAhcdEr_Ja"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "print(\"Loading Food-101 dataset...\")\n",
        "dataset = load_dataset(\"food101\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KODHj2yo25YY"
      },
      "outputs": [],
      "source": [
        "train_length = len(dataset[\"train\"])\n",
        "test_length  = len(dataset[\"validation\"]) // 2\n",
        "val_length = test_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoP-iuU1umFM",
        "outputId": "a5486c63-e91a-4c86-ac54-e0788c137a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training samples: 75750, validation samples: 12625, test samples: 12625\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Subset(dataset[\"train\"], range(train_length))\n",
        "test_dataset = Subset(dataset[\"validation\"], range(test_length))\n",
        "val_dataset = Subset(dataset[\"validation\"], range(test_length, test_length + val_length))\n",
        "\n",
        "print(f\"training samples: {train_length}, validation samples: {val_length}, test samples: {test_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMRtl3uV9b-p"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=custom_collate, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2, collate_fn=custom_collate)\n",
        "test_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=2, collate_fn=custom_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGU_3jbwma2p"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        #residual function\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, num_block, num_classes=101):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True))\n",
        "        #we use a different inputsize than the original paper\n",
        "        #so conv2_x's stride is 1\n",
        "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "\n",
        "\n",
        "        # we have num_block blocks per layer, the first block\n",
        "        # could be 1 or 2, other blocks would always be 1\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.conv2_x(output)\n",
        "        output = self.conv3_x(output)\n",
        "        output = self.conv4_x(output)\n",
        "        output = self.conv5_x(output)\n",
        "        output = self.avg_pool(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "def resnet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "model = resnet18()\n",
        "model = model.to(device)\n",
        "print(\"Model created:\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F1DYE1nn3nQ"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "i = 0\n",
        "\n",
        "for batch in val_loader:\n",
        "  #print(batch[\"pixel_values\"].shape)\n",
        "  inputs, labels = batch[\"pixel_values\"].to(device), batch[\"label\"].to(device)\n",
        "  #print(model(inputs))\n",
        "  for item in range(batch_size):\n",
        "    image = batch[\"pixel_values\"][item].to(device)\n",
        "    output = model(image.reshape(1, 3, 128, 128))\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    image = image.cpu().numpy().transpose((1, 2, 0))\n",
        "    plt.imshow(image)\n",
        "    print(\"THE LABEL: \", batch[\"label\"][item].item())\n",
        "\n",
        "    print(\"Prediction: \", predicted.item())\n",
        "    break\n",
        "  #   pass\n",
        "  break\n",
        "  # pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IC14JmmnW02Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "model.load_state_dict(torch.load(\"/content/model.pth\", map_location=torch.device(\"cpu\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF8_vToAoq4j"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-6, weight_decay=1e-4)\n",
        "\n",
        "num_epochs = 1\n",
        "print(f\"Training for {num_epochs} epochs...\")\n",
        "\n",
        "loss_x = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    loss = 0.0\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        inputs, labels = batch[\"pixel_values\"].to(device), batch[\"label\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        # loss_x.append(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"Batch {i+1}/ {train_length // batch_size}, Loss: {loss.item()}\")\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(val_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            voutputs = model(vinputs)\n",
        "            vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print('LOSS train {} valid {}'.format(loss, avg_vloss))\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kjDSAEgXosxa"
      },
      "outputs": [],
      "source": [
        "save_path = \"custom_cnn_model.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model saved to {save_path}\")\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        inputs, labels = batch[\"pixel_values\"].to(device), batch[\"label\"].to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Validation Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhsjAdG42ktM"
      },
      "outputs": [],
      "source": [
        "loss_x = [x.item() for x in loss_x]\n",
        "\n",
        "plt.plot(range(len(loss_x)), loss_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkiSNDdB4tCN"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "i = 0\n",
        "\n",
        "correct = {}\n",
        "totals =  {}\n",
        "\n",
        "for batch in val_loader:\n",
        "  inputs, labels = batch[\"pixel_values\"].to(device), batch[\"label\"].to(device)\n",
        "  for item in range(batch_size):\n",
        "    image = batch[\"pixel_values\"][item].to(device)\n",
        "    output = model(image.reshape(1, 3, 128, 128))\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "    label = batch[\"label\"][item].item()\n",
        "\n",
        "    if predicted == label:\n",
        "      correct[label] = correct.get(label, 0) + 1\n",
        "    totals[label] = totals.get(label, 0) + 1\n",
        "\n",
        "for i in correct.keys:\n",
        "  print(f\"Label {i} accuracy: {correct[i]/totals[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14xAwRj06g77"
      },
      "outputs": [],
      "source": [
        "for i in sorted(correct.keys()):\n",
        "  print(f\"Label {i} accuracy: {correct[i]/totals[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqxT0o0P6qci"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}